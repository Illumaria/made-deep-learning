# Fundamentals of Deep Learning (MADE S02E02)
This repository contains notebooks for the Fundamentals of Deep Learning course.

**Tip #1:**

Loading the entire repository can take a considerable amount of time. A single folder can be downloaded via [DownGit](https://downgit.github.io/).

**Tip #2:**

Sometimes GitHub failes to render a notebook. In that case use [nbviewer](https://nbviewer.jupyter.org/) — it works like a charm!

### Lectures

Legend: ![](./icons/pdf.png) — slides, ![](./icons/jupyter.png) — code, ![](./icons/youtube.png) — video.

Week | What | Where | When
:--: | :--: | :---: | :--:
[1](https://data.mail.ru/curriculum/program/lesson/16355/) | Введение в глубокое обучение: нейрон, перекрёстная энтропия, градиентный спуск, Numpy, логистическая регрессия. | [![](./icons/pdf.png)](https://github.com/Illumaria/made-deep-learning/blob/master/01-intro-dl-logreg-20-01-2021/01_intro_dl_logreg.pdf) [![](./icons/jupyter.png)](https://github.com/Illumaria/made-deep-learning/blob/master/01-intro-dl-logreg-20-01-2021/01_numpy.ipynb) [![](./icons/jupyter.png)](https://github.com/Illumaria/made-deep-learning/blob/master/01-intro-dl-logreg-20-01-2021/01_logreg.ipynb) [![](./icons/youtube.png)](https://youtu.be/WiFQF8sTxko) | 20.01.2021
[2](https://data.mail.ru/curriculum/program/lesson/16356/) | Полносвязные сети, метод обратного распространения ошибки, стохастический градиентный спуск, производные по матрицам. | [![](./icons/pdf.png)](https://github.com/Illumaria/made-deep-learning/blob/master/02-fc-nets-backprop-27-01-2021/02_fc_nets_backprop.pdf) [![](./icons/jupyter.png)](https://github.com/Illumaria/made-deep-learning/blob/master/02-fc-nets-backprop-27-01-2021/02_fc_nets_backprop.ipynb) [![](./icons/youtube.png)](https://youtu.be/OUsKEHaOLtE) | 27.01.2021
